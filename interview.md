# 自我介绍
面试官您好，我是天津工业大学22届的本科学生，我叫熊海成。

可能您看到我的简历会比较好奇我的本科专业，对，我的本科专业就是“生化环材”四大天坑之一——材料。
当年添志愿的时候本来计算机是排在最前面的，结果阴差阳错地又把材料调到了前面，
后来又发生了一系列的事情触动了我，最后决定自学计算机，然后就这样一步步的靠自己走到现在，
接触了许多编程语言、接触了Linux、接触了开源社区。
这期间也确实锻炼了我很多能力，特别是独立思考与学习的能力、解决问题和沟通的能力；
也学到了很多知识，像Linux、C++、Go、Python等等，
特别是计算机的基础知识，因为我自己非科班嘛，所以我特别重视基础，这样我以后才能有更好发展潜力。
嗯，以上大概就是我想说的。


# HR面
**STAR法则**
1. 这件事发生在什么时候？                       ———————S
2. 你要从事的工作任务是什么？                   ———————T
3. 接到任务后你怎么办？                         ———————A
4. 你用了多长时间获得完成该任务所必须的知识？   ———————深层次了解
5. 你在这个过程中遇见困难了吗？                 ———————顺便了解坚韧性
6. 你最后完成任务的情况如何？                   ———————R


* 问：最有成就感的事情？
* 答：就是每次通过自己的理解，掌握了一个知识点的时候，或者总结出一套规律或经验的时候就会有点小成就感。
    比如我自己就总结了许多经验法则，就写在了我的项目一的笔记里。
    其中有些是看书吸收过来的，有些就是我凭自己经验总结的。
    比如C++代码风格的规范与优化、代码逻辑的表达步骤以及简化等等。
    当把这些理论应用到实际写代码过程中时没出错，特别是把我这些理论分享给其他人的时候，也特别有成就感。


* 问：经过努力克服的事？
* 答：都说万事开头难，别人都是“师父领进门，修行在个人”，我是连个便宜师傅都没有。
    我是从大一下期开始自学计算机的，刚开始的时候真的太痛苦了，好多东西都不会，甚至都不知道自己不知道什么。
    然后每天都去网上搜资料，先规划好学习路线，然后买书来看。
    后来慢慢地把知识体系建立起来了，视野越来越宽，学习习惯也养成了，现在学起来就顺畅多了。
    因为有这些基础知识体系，就能很好的理解甚至推导新知识新技术。
    比如学了计算机网络的基础知识，就能去推导怎么做内网穿透呀，去推导docker容器的网络模型呀之类的


* 问：你有什么缺点？
* 答：缺点可能就是注意力有时不集中。
    高中的时候我们老师就给我们测试过，就给我们一张图，
    只要你注意力专注于观察图片中心，图片周围的颜色就会消失。
    我旁边一个挺聪明的同学说她看到周围颜色立马就消失了，而我看了好久才消失，那时候就觉得他好厉害哦。
    我看书的时候也会注意力不集中，有时候真得感觉我都不识字了，一段话来来回回看几遍。
    还有些时候就是在学新知识点的时候，老想着去回忆一下之前学的，怕忘记，这导致我看书背书进度都不快。


* 问：你有什么优点？
* 答：我的觉得我的优点就是总结归纳的能力不错。我项目一里的48万字的笔记都是我的知识体系的归纳总结。
    我觉得学计算机需要两种能力特别强，就是总结和抽象的能力，想要理解书里的那些知识和模型真得特别需要这两种能力。
    我每次学习完后都会把知识点和想法梳理并整理到笔记里，笔记也随着我不断深入学习而不断变化。
    比如我C++和Linux那几篇笔记，基本上算是重写了有3遍，每次重写都是一种理解上的升华吧。
    我觉得写笔记的过程就是在和自己对话的过程，就像费曼学习法嘛，不过我是把知识将给自己听。


* 问：期望薪资？
* 答：就技术面试官对我的评价，根据您的经验来看，我的薪酬范围应该是多少呢？
    * 参考对方公司公开薪资表
    * 参考上份工作×130%左右
    * 面试效果好就报高点，不好则报低点
    * 尽量把合同上的薪资谈高（月薪）


* 注意，技术面试官谈薪资时，答：“现在还不确定，HR需要综合评定。”（无法回避就报低点）


* HR反问
    * 薪资结构
    * 年终奖
    * 五险一金
    * 加班情况
    * 加班费计算
    * 升职加薪的规章制度
    * 年假安排等


# 技术面
## 反问
* 项目组负责的产品和具体工作内容？
* 用的哪些编程语言？
* 项目组里C++标准大概都是用的哪版？
* 新加入的成员一般负责做什么？
* 需要我补充哪方面的知识或者锻炼哪方面能力呢？


## 项目
### SeeCheatSheets
这个项目本来的目的是作为一个我个人学习笔记仓库，囊括了我个人所学的绝大多数知识与技能，
仓库里一共包含了30多篇用markdown撰写的文章笔记，总共有40多万字。
项目的目的本来是为了整理自己所学的知识，相当与一个思维导图，让我可以很方便的随时复习，加深印象。

> 这相当于是费曼学习法吧，每次写文章作笔记都是一个与自己对话的过程，给自己讲解每一个知识点，
> 最后将知识吸收变为自己的理解然后记录都文章里。

后来呢，因为项目里有许多记忆性的知识，比如C++标准库、POSIX API、Linux命令参数等等；
虽然这些大多都记得，我有刻意的去背、去记忆这些，但总有时候还是需要查询。

为了方便快速查询这些笔记，我用C++编写构建了一支程序，
可以根据关键字快速地搜索笔记片段并利用ANSI转义序列对markdown文本进行语法解析并高亮。
因为我平时学习和生产环境都是在终端命令行里进行的，所以查询结果直接在终端打印出来，很方便。
如果文本显示超出屏幕宽度还会将结果通过管道送给pager程序显示。
项目的github主页上展示了有效果图。

技术上的特点话，主要就是围绕“可扩展性”进行设计；
因为markdown本身语法由许多语法区块构成，比如列表区块、引用区块、代码区块等等；
而且，不同版本的markdown语法都有各自独特的语法元素，比如比较流行github风味的版本就支持@用户和提及issue等等，
markdown的作者都没有官方地统一标准，所有很有必要去思考如何提高程序的可扩展性；

我的设计上呢，首先就是为不同的语法模块设计一个抽象基类，这个抽象基类的接口大致有3个：
* 第一个方法用于判断当前行是否为某语法区块的开头
* 第二个方法用于判断当前行是否为某语法区块的结尾
* 第三个方法就是对开头到结尾之间的文本内容进行语法解析并高亮

但这儿有个问题就是，一个类型的语法模块可能依赖于另一个类型的语法模块；
比如说，判断是否结束“列表区块”就依赖于当前行是否是引用区块的开头、代码区块的开头等等，
还有比如，大多数语法区块都依赖“解析普通段落的语法区块”，用它的语法高亮方法来解析部分内容；

如果各个语法模块之间直接相互引用的话，将类型信息硬编码进代码中，
就会导致模块间非常高的耦合度，从而导致各个模块没法独立的变换扩展，
只要对一个模块进行修改扩展，就要同时修改其他所有依赖它的模块；
这时候为了降低各个语法模块间直接相互引用而导致的耦合，就需要引入“中介者模式”；

首先我需要设计一个中介者类，所有属于同一个markdown语法版本的语法模块都向同一个中介者注册自身，
各个语法模块与其他语法模块间的相互调用都需要通过中介者来进行，
这样每个语法模块都可以独立的修改扩展而不影响到其他模块，
实现上就是在中介者内部用哈希表键值对来存储各语法模块的指针，
注册时，比如列表区块就注册键值为list，引用区块就注册键值为quote等等；

同时，因为中介者聚集封装了各个语法模块而形成一个用于完整Markdown语法模块，
这样中介者去除也算是一个表观模式中的表观类吧；
很自然的，我只需要一个中介者，所以又将这个中介者设计成单例模式；

除此之外，还有一个特点是，语法模块的抽象基类的构造函数比较特殊，
所有派生自它的子类在构造其对象实例时都自动地向中介者单例注册自身；

这样设计下来，每当我们要设计添加一个语法高亮模块时，
* 就先派生自抽象基类，
* 然后实现基类接口，
* 最后定义一个静态变量；

当程序启动后，在调用main函数之前，会先调用静态变量的构造函数，
这样就会调用基类的构造函数，然后自动地向中介者单例注册那些引入的语法模块。
而语法模块的设计分为两部分，两个文件，
* 一个是头文件，里面有派生类的定义，以及该派生类的一个inline的静态变量，
* 另一个是实现文件，就是实现了头文件中的接口。

这样，只要在主模块文件中include语法模块的头文件，就相当于自动引入了该语法模块。
想要修改Markdown版本，实现新的语法模块，然后引入新的头文件就行了。

这个设计最大的问题在于，引入的头文件模块都自动的向一个中介者注册自身，
所以运行时只能同时存在一个Markdown语法版本，这对于我自己来说是可接受的，而且这种设计更方便也更有趣；

如果正常设计的话，就老老实实地在中介者的构造函数中手动注册各个版本的语法模块，形成完整的markdown语法模块。
不同版本的markdown语法就只要将各个版本的语法模块组装起来就行了。

大概设计架构就是这样，剩下的就是语法解析算法的实现了。
解析算法上比较特殊的就是标题区块与代码区块的语法解析吧，
这两个语法模块解析都需要获取终端窗口大小，这就需要调用Posix标准的系统api来获取，
同时也需要计算每一行字符的显示宽度，这就涉及到了简历上第四个项目了。
最后的话，就是普通段落区块的解析算法比较麻烦，需要用栈来记录行内emphasize元素的开启与关闭，
比如斜体粗体呀、内联代码、下划线等等，关闭的时候需要结束当前元素颜色显示，同时恢复外层元素的颜色显示。

* 问：如何实现在基类构造函数中注册派生类实例？
* 答：这就涉及到C++的多态原理。派生类的数据成员其实可看作两部分，一个是派生类部分，一个是基类部分。
如果类中定义了有虚函数，就会引入一个隐式的数据成员——虚指针，虚指针指向虚表，
虚表里存储了虚指针所在类的运行时的真实类型信息，以及该运行时类型的虚函数入口地址；
派生类部分与基类部分都有虚指针，所以我们基类的this指针就相当于把派生类的指针转换为基类指针，从而形成多态，
然后通过指针调用虚函数时，就会根据指针找到虚表，然后找到相应的虚函数入口地址，这个过程就是动态绑定。


### DotFiles
这个项目其实也没啥说的，就是作为两年多的Linux用户、Linux的热爱者，我自己所积累下来的整个开发环境的配置。
项目里提供了一个Shell脚本，可完整的还原我自己的整个开发环境，方便我重装，
俗称“折腾”嘛，linux用户都挺爱折腾的。
折腾的过程中我们得不断的去思考，
不断地去发现问题、定位问题、搜索解决方案、尝试自己解决，经常会引发我自己去思考一些底层的设计原理。
这确实是很锻炼一个人的独立思考能力、解决问题的能力和意志力。
折腾了两年下来，其实更重要的是这个过程而非结果。这个项目也是记录了我个人的成长过程吧。

比如国内DNS污染问题，我经常访问github会受到域名污染的问题，特别是校园网。
一开始我不知道域名污染，我想应该不止我一个人访问github很慢吧，我就去搜“github访问很慢怎么办”？
结果就知道了，哦，是域名污染的原因，根据我学的计算机网络的知识，知道DNS在网络中扮演什么样的角色，
也就明白为什么改hosts文件会有效果。

后来不满改hosts的方法非常麻烦，特别是对于github博客的域名，就是github.io，每个博客的域名都是不一样的，
所以没法通过修改hosts文件来解决，于是我就想，有没有其他方法从根上解决域名污染呢？
诶，我就想到直接用github的权威DNS服务器，这样就不会有域名污染的问题了吧。
实验倒是成功了，但是速度有点感人，太慢了。
然后我就想，能不能只对github的域名使用他家权威DNS服务器，就是对于指定的域名使用指定的DNS服务器来解析。
然后我就去搜，在stackoverflow上找到了答案，说是linux内核并不支持这样做，需要自己搭建DNS服务器。
然后就顺藤摸瓜，去修改NetworkManager服务的配置，让NetworkManager将DHCP获取的DNS服务器IP写到另一个文件中去，
而将resolv.conf中的本地使用的DNS服务器地址改为本地回环地址，
然后手动通过systemd启动dnsmasq服务，然后让dnsmasq自动读取之前NetworkManager写入的本地DNS的IP地址，
作为默认的DNS服务器，然后配置当解析github的域名的时候使用github自己的DNS服务器

chfs、systemd、转发、SELinux、FreeDesktop

字体合成、终端、字体矢量图、字体回滚、搜索解决方法

就像这样，问题一个一个得被解决，配置越来越多，开发环境越来越舒服。
所以这个项目对我来说，是一个我成长的过程吧。

### SpaceVim
SpaceVim是一个社区驱动开发的模块化的vim发行版，它利用模块的形式来管理插件集合。
SpaceVim在2018年立项，我也在立项不久就接触SpaceVim。
当年vim配置那是群魔乱舞，百花齐放，现在有了SpaceVim其实很大程度上改善了这一状况，
因为在大多竞品当中，SpaceVim是社区最庞大，开发最活跃，功能最完善，文档最齐全的。
很大程度降低了vim的门槛，对新手更加友好。
上游维护者还希望我们在高校中推广SpaceVim，当然我都去推广我自己的fork分支版本了。

项目中模块化管理确实是一个非常棒的设计，如今SpaceVim有这么多包括我在内的贡献者其实模块化设计作了很大贡献。

我作为一个开源贡献者，累计提交了共3个PR，共修复了2个bug和1个特性增强；
1个bug是关于文件内容匹配搜索的大小写敏感问题，1个是关于上游插件更新接口导致的兼容性问题；
增强的特性是对一些插件的加载规则进行修改再加以测试，提高加载速度的同时保证用户的对此的透明性。

虽然贡献的不多，但我对于我自己的fork分支版本进行了大量的修改。
总共修改了有40多个源文件，累计修改了将近4000行源代码，同时还写了有比较完善的使用文档。

作为开源贡献者，同时也是SpaceVim社区中的一员，经常会参与讨论一些项目相关话题，
我想这也是会块源社区做贡献的一种方式。

有时会有新手问vim本身的如何去配置，我一般看到都会耐心跟他们讲解vim的各种概念和功能特性；

有时会交流一些技术问题，比如向他们学到的，通过适时检测vim的窗口布局来实现让一些辅助窗口不影响vim退出；

有时我也会提出一些我自己的设计，比如给快速运行插件添加个功能，通过匹配文件内容来自动添加一些参数，
比如我在C++中引入并发相关的头文件，就自动添加编译器参数`-lpthread`链接linux线程库，
还有用C重写计时器，可以计时更精准，我还可以添加功能来获取程序的退出码和中断信号。

团队合作中，沟通其实非常重要。

而且这也是我第一次大规模的阅读别人的代码，其实还是很有挑战的。


我就说说我自己作了哪些修改吧：
* * * * * * * * * *
* **图标**：基于文件名、基于vim内建类型
* * * * * * * * * *
* **自动补全**：语义补全引擎与结对符补全，issue，实现
* * * * * * * * * *
* **语法检测**：cppcheck、clangtidy
* * * * * * * * * *
* **颜色主题**：针对C++
* * * * * * * * * *
* **字符画**：独角兽、不可描述
* * * * * * * * * *
* **状态栏**：算法修改，根据当前窗口宽度来选择展示的内容，行列号
* * * * * * * * * *
* **Fcitx与Fcitx5**：四种状态、问过上游
* * * * * * * * * *
* **FlyGrep文件内容搜索**：大小写敏感，PR
* * * * * * * * * *
* **QuickRun快速代码运行**：替代上游
    * 内建终端（方便）
    * 计时器（Linux api、更精准、派生子进程、前台进程组、信号、返回码、中断信号）
    * CGroup限制内存使用
    * 自动检测时间戳
    * 窗口隔离
    * 参数设置（设置编译器参数、运行命令、IO重定向）
    * 无伤移植
* * * * * * * * * *
* **文件树**：绑定快捷键到GUI程序
* * * * * * * * * *
* **tmux**：交互
* * * * * * * * * *
* **C模块**：三个插件（语义补全引擎、语法检测引擎、我的代码快速运行插件）统一C++标准版本。
* * * * * * * * * *
* **文档**：精简齐全，不用过脑
* * * * * * * * * *


整个项目对我而言，其实是对我自身综合能力的锻炼吧，毕竟这么大个项目，团队合作很重要。
而且这也是我自身第一次大量的阅读别人的源码，而且还是自己没熟练掌握的语言，
所以对我而言，需要大量的思考别人的设计，才能修改成我想要的样子。


## 八股
### 数据结构
* 二叉搜索树
    * 每个节点有两个子节点，父节点的键值大于左子节点，小于右子节点
    * 特点：时间复杂度与树的深度有关，平均为O(log(N))。
    * 缺点：但最坏的输入情况（所有数据已排序）会使二叉树退化为链表，导致增删查操作时间复杂度均为O(log(N))
* AVL树
    * 每个节点保持左子树与右子树高度差绝对值（平衡因子）不超过1，每个节点额外记录树的高度
    * 若某次插入造成一个最深的节点的平衡因子大于1则进行旋转，从而恢复该子树的高度
        * 如果插入左子节点的左子树或右子节点的右子树造成不平衡，则进行单旋转（画图）
        * 如果插入左子节点的右子树或右子节点的左子树造成不平衡，则进行双旋转（画图）
    * 缺点：平衡要求太严格，插入与删除导致频繁的旋转操作，开销太大
* 红黑树
    * 每个节点要么红色要么黑色
    * 根节点为黑色
    * 红色节点的子节点必须是黑色
    * 从一个节点到一个null指针的每一条路径必须包含相同数目的黑色节点
    * 特点：红黑树的高度最多是2*log(N+1)，相对AVL树是在树的高度平衡与增删操作性能之间的折衷
* B+树
    * 除了根外，所有非叶节点的儿子数在M/2与M之间，防止M叉树退化
    * 数据只存储在叶节点上，所有叶节点都在相同深度上，且数据项个数在L/2到L之间（页分裂）
    * 特点：相对CPU密集型，IO密集型的应用的性能瓶颈在于磁盘IO的速度，
        利用B+树大大降低了树的深度（平均$log_{M/2}N$），也就大大减少了节点访问次数，从而减少了IO次数。
        而且利用B+树可以进行范围查询。

* 散列表
    * 哈希冲突：
        * 链表法：
            * 特点：将哈希值相同的元素放到一个链表中，相等元素放到一起且新插入的放前面，
                当填充因子过大（一般阀值为0.75）时进行rehash，防止链表过长
        * 线性探测：
            * 特点：哈希冲突时会以线性函数为下标增量(如f(i)=i)寻找下一个空闲位置存放元素
            * 缺点：会逐渐形成一次聚集，寻找合适位置所需时间变大
        * 平方探测：
            * 特点：哈希冲突时会以二次函数为下标增量(如f(i)=i^2)寻找下一个空闲位置存放元素
            * 缺点：当表的大小为素数且表至少有一半是空的，则必定能插入一个新元素，否则很可能插入失败
        * 双散列：性能开销较大


### 操作系统
* 加法器
    * s1 = A ^ B
    * c1 = A & B
    * s2 = s1 ^ c
    * c2 = s1 & c
    * s  = s2
    * c  = c1 ^ c2

* 减法器
    * x - y
        = x + 1111 - y + 1 - 10000
        = x + ~y + 1
    * -y = ~y + 1

* 整形编码
    * 无符码与补码
    * 扩展、截断、转换
    * 求逆、加法、乘法

* 浮点数编码
    * 符号-阶码-尾数
    * 非规格化（正负0）、规格化、无穷、NaN
    * 精度：无结合律、近似比较

* 进程内存布局（从低地址到高地址）
    * 代码段：ELF中的.text与.rodata区
        > .text保存机器指令，.rodata保存诸如字符串字面量与浮点数字面量；
        > x86指令浮点数没有立即数，所以需要存储到.rodata；而整数有立即数，可以直接存储到机器指令中
    * 数据段：ELF中的.data与.bss区
        > .data保存全局和静态变量，区别在于.bss只记录未初始化或初始化为0的全局和静态变量而不分配空间，
        > 为节省空间，在加载时才分配内存并初始化为0
    * 堆：
        > 动态内存，高级语言的内存分配器帮助我们管理（内存分配、碎片整理、垃圾回收等等）
    * 共享段：
        > 调用动态共享库时会将动态库的代码段和数据段映射到这里
    * 栈：
        > 保存运行时数据
    * 内核保留空间：起始于$2^48$
        * 内核代码与数据
        * 物理内存映射
        * 当前进程专属信息（task、thread_info、内核栈等等）

* 运行时栈
    * 函数参数
    * 返回地址
    * 被调用者保留寄存器值
    * 局部变量
        * 结构与数组
        * 取地址的变量
        * 寄存器不足

* 对抗缓冲区溢出攻击
    * 地址空间布局随机化(ASLR)
        > 运行时随机设置关键区域的地址空间，同时保证堆、共享段、栈的相对地址不变；
        > 随机化范围大约$2^32$，加大“空操作雪橇”暴力破解难度
    * 栈破坏检测
        > 在栈帧中的返回地址前面设置运行时随机的“金丝雀值”，并将该值放在只读寄存器中，
        > 函数返回前对比“金丝雀值”与只读寄存器值是否相等，若不等则说明发生了缓冲区溢出
    * 限制可执行代码区域

* 静态链接
    * 符号解析：将多个目标文件中的符号定义与符号引用绑定起来
        > 实现上维护三个集合：未绑定引用集合、定义集合、文件集合。链接器依次解析命令行参数文件
    * 重定位：将多个目标文件聚合成一个文件后，一些引用地址需要修改
        > 外部函数、内部全局变量、外部全局变量；
        > 内部函数因为相对地址不变而无需重定位

* 动态链接
    * 编译时：提取动态库符号信息
    * 启动时：调用链接器加载动态库
        > 动态库搜索路径：
        1. 可执行文件中指定
        2. 环境变量LD_LIBRARY_PATH指定
        3. 配置文件/etc/ld.so.cache指定
        4. 系统默认路径/lib
    * 内存映射：代码段母本、数据段副本（相对代码段位置不变）
    * 变量引用：立即绑定到GOT表
    * 函数引用：延迟绑定到PLT表

* 虚拟内存
    * 优点：
        * 使系统更高效地利用内存
            * 进程看起来连续的地址空间页面，实际上可能被分散地映射到了物理内存各处，系统可以很好的利用一些空间碎片
            * 进程的虚拟地址空间不仅可以映射到物理内存，还可以映射到磁盘空间，
                系统利用LRU算法会在内存紧张的时候将一些不常用的页面冲刷到磁盘swap空间，下次访问时通过缺页处理再加载回来。
                整个过程对进程透明。
        * 简化内存管理：
            * 为每个进程提供一致的地址空间，可以简化链接、简化加载、简化共享、简化内存分配
        * 内存保护机制：
            * 每个进程的地址空间都相对独立，从而避免地址空间被其它进程破坏
                > 不同进程中相同的虚拟地址一般映射到不同的物理地址，除非是共享段或者fork的子进程因为COW机制而与父进程暂时共享地址空间
    * 地址翻译：
        * 当CPU指令进行访存操作时，先将虚拟地址送给MMU进行翻译
        * 将虚拟地址分为两部分：虚拟页号与偏移量
        * 然后从页表基址寄存器读取页表起始地址访问页表（页表有单独的高速缓存TLB）
        * 根据多级页表一层层进行索引，最终得到对应的物理页号；同时根据偏移量去高速缓存中找出可能的数据
        * 当翻译完成后检查提前找出的数据地址是否匹配，如果匹配就加速的数据访问，若不匹配则通过物理地址重新访问高速缓存
    * 页与段：
        * 页是内存分配/翻译的基本单位，段将连续的功能相同的页组织关联起来
        * 页表存储信息包括：是否已分配、超级权限、可读、可写、可执行

* 异常控制流
    * 异常类型：
        * 中断（异步）
        * 陷入（同步）
        * 故障（同步）
        * 终止（同步）
    * 异常处理：
        * CPU发生异常控制流
        * 保存寄存器状态
        * 通过“异常表基址寄存器”访问“异常表”
        * 执行当前“异常号”对应的“异常处理程序”
        * 恢复寄存器状态，继续执行当前指令或下一条指令
    * 内核模式与用户模式
        * 由某个寄存器的模式位表示
        * 处于内核模式的进程可以执行指令集中的任何指令，访问系统中任何内存位置
        * 用户模式使用用户栈，内核模式使用内核栈
        * 从用户模式变为内核模式的唯一方法就是通过异常控制流
    * 进程/线程上下文切换
        * 线程是调度的基本单位，进程是资源分配的基本单位
        * 切换寄存器中的值，特别是PC状态
        * 切换页表基址寄存器中的值，即切换整个虚拟地址空间，导致大量高速缓存失效

* 进程状态
    * (R)运行           ：该进程在调度队列中
    * (S)可中断睡眠     ：该进程在响应事件等待队列中
    * (D)不可中断睡眠   ：该进程不响应异步信号以保护控制流不被打断
    * (T)停止或跟踪     ：该进程被暂停或不能响应SIGCONT的跟踪状态
    * (X)退出           ：该进程即将退出
    * (Z)僵尸           ：该进程已经终止但还未被父进程回收，保留了内核栈、task、thread_info

* 进程间通讯
    * 管道(pipe)
        * 用于单向通讯，一个fd用于读，一个用于写
        * 只能在有亲缘关系的进程间使用，因为pipe读写端的文件描述符只能通过fork子进程继承来传递
        * 缓冲区大小有限
        * 应用程序stdin一般默认全缓冲，进程会循环阻塞直到缓冲区读满或者触发EOF，
            如果管道用于双向通讯，很可能造成缓冲区未满而另一边又试图读取输出而非触发EOF，造成双方循环等待的死锁局面。
            一般这种情况用伪终端来通讯，因为stdin对于终端都是行缓冲。
    * 伪终端(pty)
        * 模拟终端
    * 套接字(socket)
        * 用于双向通讯
        * 可以在任一两进程间使用，甚至两进程不必在同一系统上
        * 需要对传输的数据进行解析
    * D-Bus
        * 类似总线，可以让多个进程同时进行通讯
    * 消息队列
    * 共享内存
    * 信号量
    * 信号

* 死锁必要条件
    > 简而言之，两线程互相请求对方已持有的互斥锁，导致两线程均阻塞等待对方解锁。
    > 可以通过以相同顺序加锁解决（破坏循环等待条件）
    * 互斥条件
    * 不可抢占条件
    * 请求和保持条件
    * 循环等待条件

* 多线程与多进程
    * 进程的创建、销毁、切换的开销较大
    * 同进程的线程间共享虚拟地址空间，通讯更方便，也更容易出错
    * 一个线程挂掉可能导致整个进程挂掉
        * 主线程退出
        * 某线程调用exit函数
        * 某线程接受信号而终止进程

* （无栈）协程
    * 两个栈帧
        * 一个是分配在栈上的普通栈帧，存储返回地址、声明周期仅限于该线程片段的变量等，虽协程的恢复与暂停而产生和销毁
        * 一个是分配在堆上的共享栈帧，存储协程句柄、伴随协程整个声明周期的变量等，在协程创建时产生，协程返回时销毁
    * 协程的切换完全在用户态进行
    * 利用协程编写异步事件驱动状态机，取代回调函数，可极大简化编程
    * 一个线程可创建多个协程，即多个协程占用一个线程的控制流，无法并发来充分利用CPU，适用于IO密集型应用

* ASIO的Proactor模型
    > 利用gdb调试追踪调用栈，观察源码，可简化为两个组件
    * 引发器(Initiator)
        > 如socket
        1. 启动异步操作，如低速IO、计时器等等，利用系统调用或多线程实现异步，保证快速完成返回
        2. 注册该异步事件（对应的文件描述符）及其对应的回调函数
    * 前摄器(Proactor)
        > 如io_context
        * 如果完成事件队列中存在任务则取出（线程安全）
            1. 执行其回调函数
            2. 回调函数作为Initiator再次启动异步操作、注册异步事件（进入下一个状态）
        * 如果完成事件队列中无任务则阻塞
            1. 利用操作系统接口（如epoll）实现多路复用阻塞监听
            2. 当异步操作完成时，会触发监听事件，唤醒线程进入下一次循环（此时队列非空）
    * 服务器一般存在3类状态机
        * 连接状态机，负责与客户端通讯
        * 监听状态机，负责与客户端建立连接状态机
        * 多路复用状态机，负责运转其它状态机

* 无锁队列
    > 并发问题的核心：一个线程读/写一个可能同时会被其他线程修改的共享数据时，会产生竞争条件。
    * 本质：我还专门去看过无锁队列的那篇论文，这个无锁队列算法利用CAS原子操作来实现“乐观锁”，从而让线程无阻塞的运行
    * 链表结构：维护head指向上次被删除的节点（哑节点），维护tail指向队列最后一个节点，前开后闭区间，如此可表示空集
    * enqueue操作的核心原子操作：`CAS(tail->next, NULL, new_tail)`和`CAS(tail, read_tail, new_tail)`
    * dequeue操作的核心原子操作：`CAS(head, read_head, read_head->next)`
    * dequeue操作的ABA问题解决：
        > 问题描述：head可能在CAS之前被修改多次，但因内存重用而致最后一次修改时将head重新改回了read_head，
        > 导致当前线程误以为head与read_head有效匹配
        * Double-CAS(指针，版本号)
        * 引用计数，当没有线程持有read_head时才能销毁对应节点（避免内存重用）
        * 使用循环数组
```cpp
void push(T val) {
    Node* newTail = new Node{};
    newTail->val_ = val;
    newTail->next_ = nullptr;
#ifdef V1
    while ( tail_->next_->compare_exchange_week(nullptr, newTail) );
    tail_->exchange(newTail); // 缺点：如果此处更新失败会导致其他所有线程永久阻塞
#elif V2
    for ( ; ; ) {
        // 每次循环读取新的tail_
        Node* readTail = tail_;
        // 尝试更新tail_->next抢占enqueue权
        if ( !readTail->next_->compare_exchange_week(nullptr, newTail) ) {
            // 若抢占失败，则占用者可能处于中间态，尝试帮助其更新tail_
            tail_->compare_exchange_week(readTail, readTail->next_);
        } else {
            // 若抢占成功，则此时处于中间态，接下来更新tail_
            tail_->compare_exchange_week(readTail, newTail); // 缺点：后两个CAS操作可能导致无效竞争
            break;
        }
    }
#elif V3
    Node* readTail = tail_;
    Node* oldTail = readTail;
    do {
        // 把readTail看作是接近真正tail的一个节点，尝试移动至真正tail
        while ( readTail->next_ ) // 缺点：遍历开销可能较大，p个并发量则最大需前进2p-1步
            readTail = readTail->next_;
    } while ( readTail->next_->compare_exchange_weak(nullptr, newTail) )
    tail_->compare_exchange_strong(oldTail, newTail);
#endif
}
```

### 网络
* 三次握手的原理
    * 防止旧的重复连接的初始化（旧SYN先到，响应RST）
    * 同步双方的初始序列号

* SYN泛洪攻击：发送大量合法的SYN包试图建立连接而无后续操作，占用服务器资源
    * 减少半连接状态持续时间
    * 设置最大半连接数量
    * 攻击者黑名单
    * SYN cookie（四元组+秘密数 hash）

* 四次挥手的原理
    * 全双工连接，两次握手关闭一个方向
    * 一个方向关闭后，另一个方向可能还有数据需要传输

* TIME_WAIT状态原理
    * 主动发起关闭连接的一方最后所进入会进入TIME_WAIT状态
    * 防止具有相同四元组的旧的数据包被新连接错误地接收，等待2MSL让原来连接的数据包全部过期
    * 等待足够的时间以确保最后的ACK能让对方接收从而正常关闭连接

* TIME_WAIT危害
    * 占用内存资源
    * 占用端口资源

* 出现大量TIME_WAIT原因
    * 服务器大量负载导致主动关闭大量连接
    * 客户端发起大量短连接

* 解决大量TIME_WAIT方案
    * 开启`tcp_timestamps`功能，从而在TCP报头中加入时间戳，根据时间戳来判断数据包是否过期从而可以不用等待2MSL
        同时开启下述参数：
    * 客户端开启`tcp_tw_reuse`，调用connect()时可重用一个TIME_WAIT持续超过1秒的端口
    * 服务器开启`tcp_tw_recyle`，快速重用socket，但是注意无法保证NAT后端的主机时钟同步，
        导致如果新连接中NAT服务器后端的主机时钟过慢而错判其时间戳为旧连接的数据包

* 流式数据导致粘包
    * 接受方：不及时处理
        * 后台线程预处理
        * 格式化头部信息
    * 发送放：等待缓冲区满
        * TCP紧急传送指令
        * 格式化头部信息


* 可靠数据传输：使数据按序、无缺失、不重复、信息完整地到达等对方
```python
##############################
# 发送方
##############################
维护核心变量：
下个数据段的序列号 seq
最早的已发送且未被确认的数据段的序列号 base

if 从应用层接收到数据:   # 事件一
    if 未启动定时器:
        则启动定时器
    将数据分片封装MSS
    计算下个数据段的序列号

if 接受到ACK报文:       # 事件二
    if ACK报文的序号 > base:
        更新base
        if 所有已发送数据段均已被确认:
            重启定时器
    elif 如果接受到3次冗余ACK:
        立即回传冗余ACK期望的数据段

if 定时器超时:          # 事件三
    超时间隔 *= 2
    重启定时器

##############################
# 接受方
##############################
if 接受到期望序号报文且之前数据均已确认:
    延迟回传ACK，最多延迟500 ms

elif 接受到期望序号报文且另一个报文等待确认:
    立即回传ACK累积确认两个报文

elif 接受到可以填充数据缺失间隙的报文:
    立即回传ACK累积确认

elif 比期望序号大的报文到达（数据缺失）:
    立即回传ACK指定期望序号

elif 比期望序号小的报文到达（数据冗余）:
    丢弃数据

elif 校验报文数据损坏且无法修复:
    丢弃数据
    立即回传ACK指定期望序号
```

* 拥塞控制：根据当前网络状况调整数据传输速率，从而改善整个网络环境
    * 控制已发送但未被接收的数据量不仅要小于对方接收窗口大小，同时还要小于拥塞窗口大小，通过控制拥塞窗口大小从而达到限流的目的
    * 慢启动状态：
        * 特点：拥塞窗口大小呈指数增长，初始为1×MSS
        * 转移：当计时器超时时进入，并设置拥塞窗口大小为当前的一半
    * 拥塞避免状态：
        * 特点：拥塞窗口大小呈线性增长，初始为慢启动阀值
        * 转移：当慢启动速度达到慢启动阀值，或接受到新ACK而退出快速重传时进入
    * 快速重传状态：
        * 特点：每接收一个冗余ACK就增大一个MSS，初始为慢启动阀值
        * 转移：当连续接收3个冗余ACK时进入，并设置拥塞窗口大小为当前的一半

* RUDP协议
    * ROT翻倍 vs ROT不翻倍
    * 延迟ACK vs 非延迟ACK
    * 非退让控流（取消拥塞控制机制）

* SSL协议
    > 主要功能：通讯机密性与完整性  
    > 可选功能：端点鉴别（数字证书）、密钥交换算法（服务器证书或DH算法）
    * `C->`传送：提供加密算法列表、随机数1等等
    * `<-S`传送：选择一套加密算法、随机数2等等
    * `<-S`传送：（可选）服务器证书
    * `<-S`传送：（可选）DH算法参数
    * `<-S`传送：（可选）客户端证书请求
    * `C->`传送：利用随机数计算的PMS的密文（服务器公钥加密或DH算法加密）
    * `C->`传送：（可选）DH算法参数
    * `C->`传送：（可选）客户端证书
    * `C-S`操作：双方由PMS计算出MS，再生成2个对称密码与2个MAC密码，每个方向使用一对密码进行信息对称加密与信息完整性校验
    * `C->`传送：所有握手消息的MAC
    * `<-S`传送：所有握手消息的MAC

* HTTP协议
    * 报文
        * 请求：`方法 URI 协议版本`
        * 响应：`协议版本 状态码 描述`
    * 事务
        * GET   ：安全且幂等地获取指定资源
        * HEAD  ：同GET但响应报文不含body
        * POST  ：向指定资源提交数据（可包含body，可缓存）
        * PUT   ：同POST但具有幂等性（可包含body）
        * DELETE：删除指定资源
    * 资源：
        * URL：`<scheme>://<user>:<password>@<host>:<port>/<path>;<params>?<query>#<frag>`
    * 连接与优化
        * 短连接
            * 管理方便
            * 连接的建立与断开，以及多次慢启动导致延迟高
        * 长连接
            * 同一连接中序列化进行请求-响应
            * 需要指明数据长度
            * 连接保活机制
        * 管道化连接
            * 发起请求不必等待前一个响应结束，但必须保持响应顺序，从而可能造成队头阻塞
        * HTTP/2
            * 二进制帧
            * 多路复用
            * 头部压缩
        * HTTP/3
            * 利用UPD+QUIC代替TCP，解决重传等待

* 请求web页面流程
    * **DHCP**：
        * 发起DHCP发现报文
        * DHCP主机回传DHCP响应
        * 此时可能有多个主机响应，选择其中一个发送DHCP请求
        * DHCP主机回传DHCP接收
        * 最后得到本机IP和子网掩码、DNS服务器IP、默认网关IP
    * **DNS**：
        * 请求DNS服务器解析目标域名，获取对应IP
        * 本地DNS服务器递归查询，其他网络中的DNS服务器一般都迭代查询
        * 获取的可能是目标域名的对应IP，也可能是目标域名所属的DNS服务器，后者就需要我们进行迭代查询
        * 得益于DNS缓存机制使得可以跳过大量的DNS服务器（诸如根DNS、顶级DNS等等），而且DNS使用UPD协议使查询速度更快
    * **应用层**：
        * 有了目的IP，就可以利用TCP套接字建立连接，然后进行网络间的进程间通讯(IPC)
    * **传输层**：
        * TCP协议会提供一些额外服务：三次握手简历全双工连接、可靠数据传输、拥塞控制等等
        * 将数据分片，每片最大MSS（MTU减去TCP/IP报头长度）
        * 添加TCP报头（包括源端口、目的端口、序列号等等）
    * **网络层**：
        * 查询路由表，把目的IP地址与路由表条目的掩码进行与运算，判断是否与该条目网段匹配，
            从而确定目的IP的下一跳地址（直接发送or通过网关），
            以及到达下一条地址需要从哪个网卡发送，从而确定源IP地址
        * 添加IP报头（包括源IP、目的IP等等）
    * **链路层**：
        * 此时处于网卡驱动程序，检查目的IP是否为本网卡IP，若是则直接回传到网络层（Docker虚拟网桥就是在这层捕获发送到容器中的数据包）
        * 查询arp表确定下一跳IP地址的MAC地址（如果没有则发送arp请求报文）
        * 添加MAC报头（包括源MAC、目的MAC地址等等）
    * **物理层**：
        * 此时处于网卡，进行信号转换

* 内容分发网络(CDN)
    * 单一数据中心缺点：
        * 数据中心到用户之间的距离太远从而延迟太高
        * 相同的数据多次通过相同的链路从而造成浪费
        * 单点故障后服务就会停止
    * 利用DNS服务将客户端请求重定向到一个适当的分布式集群（缓存）

* 分组交换
    * 相对电路交换优点：时分复用供多个端点共享线路进行通讯
    * 延迟包括：
        * 处理时延
        * 排队时延
        * 传输时延
        * 传播时延

* 举例：
    * Docker网络模型
    * WSL网络模型


### 数据库
#### 磁盘结构
* 行记录
    * 变长字段长度列表:NULL值列表:头部信息:主键列:事务ID:回滚指针:其他字段列
        * 头部信息：包括下条行记录指针、删除位等等
        * 主键列：若表中没有NOT NULL UNIQUE列，则自动生成隐藏的主键列
        * 事务ID：为最后一次修改该行的事务ID
        * 回滚指针：指向Undo Log
    * 行溢出处理：数据页一般为16K且规定一页至少放两行记录，
        一般将过长的列存储于外部的溢出页中，行记录中只存储指针

* 页结构
    * 头部信息:用户记录空间:空闲空间:页面目录:尾部校验
        * 头部信息：包括上/下个页面指针（页面即是B+树节点）、空闲空间地址、垃圾回收链表等等
        * 用户记录：按索引列大小排列成有序链表
        * 页面目录：将用户记录分组的有序数组，可以用二分搜索来加速页面内部的搜索
        * 尾部校验：校验数据页的完整性
    * 垃圾回收：
        1. 插入新记录时，会先取垃圾链表第一个行记录判断其空间是否足够，若足够则覆盖之，并更新垃圾链表
        2. 若垃圾链表第一个记录空间不够，则直接向页面申请空间
        3. 若空闲空间不足，但页面整体的剩余空间足够，则将页面复制到新页面并清空原来页面，再将新页面中的记录重新插回原页面进行碎片重整
        4. 若剩余空间也不足，则进行页分裂
    * 页分裂处理：当页面无足够空间存放新记录时，将一般的行记录移动到一个新页面，
        并将两个页面链接起来，新纪录放入其中并保持两个页面中的行记录有序排列

* 每连续的 64个页划分为1个区(1M)，当数据量大的时候，就会以区为单位给索引分配空间来较少随机I/O；
* 每连续的256个区划分为1个组(256M)，每组的第一个区中的头几页会存储区相关元数据，第一组第一区第一页还会存储表相关元数据；
* 功能相同的“区”组成一个逻辑段，如：非叶节点段、叶节点段、回滚段、等等；
段中各区不一定连续，将功能不同的数据区别存放于不同的区中可减少随机I/O，并利用段来组织它们；
如：叶节点段、非叶节点段、回滚段等等。

* B+树索引构造
    1. 一个页面就是B+树中的一个节点
    2. 最开始根节点页面存储用户记录
    3. 当根节点页面被装满，则将页面拷贝至新页面并进行页分裂，此时根节点页面存储子节点页面的页号（树的深度+1）
    4. 插入数据到下一层节点页面，每当进行页分裂就会递归地向上级页面中插入新页面页号和键值范围
    5. 重复，直到根节点页面被插满，到第3步

#### 内存结构
* 缓冲池
    * 借助缓存池缓存磁盘页面从而减少磁盘IO次数
    * 利用哈希表(key页号, value数据指针)与链表队列(页面数据)实现热点版本LRU算法
    * 存在flush链表记录脏页，查刷脏页有两种途径：后台线程定时冲刷，LRU算法驱逐时冲刷

* 普通LRU算法缺点：以下情况读取大量使用频度少的数据而驱逐掉热点页面
    * 线性预取：如果顺序访问某个区一定数量的页面，则异步读取下个区所有页面
    * 随机预取：如果缓存了某个区13个连续页面且均位与LRU Young子队列的前1/4则异步读取该区其他所有页面
    * 全表扫描

* 热点版LRU算法：
    * LRU队列分为两部分：前5/8为Young子队列存储热点数据，后3/8为Old子队列存储冷数据
    * 新插入的数据插入到Old子队列头部，所以只会挤掉冷数据
    * 当第一次访问Old子队列中的数据时记录下时间戳，若在一定时间后再次访问该页面则判断为热点数据，加入到Young子队列头部
    * 为减少调整频率，仅当访问Young子队列后1/4时才将其调整到队首

* 更改缓冲区
    * 当二级索引页面不在缓冲区时，它会缓存由增删改引起的页面更改，
        稍后当页面被其他读取操作到缓存池中时，将更改合并进页面中
    * 二级索引中的插入是相对随机的，引入更改缓冲区可以减少大量磁盘随机IO

#### 事务
* 原子性：整个事务中的操作要么全部提交成功，要么全部失败回滚        **(Undo Log)**
* 一致性：未成功提交的事务中所做的修改不会保存至数据库中            **(Undo Log)**
    * 每条行记录中至少有两个隐藏列，其中一个就是回滚指针，指向Undo Log链
    * 失败回滚时，利用Undo Log链可以还原旧版本的行记录

* 隔离性：其他事务对未提交事务在最终提交前其对数据库的修改的可见性  **(MVCC)**
    * 每条行记录中至少有两个隐藏列：最后一次修改该行的事务ID、回滚指针
    * 回滚指针指向Undo Log链，形成多版本链
    * 事务之间虽然写写互斥，但可同时读写
    * 可重复读模式在第一次执行查询语句时生成ReadView，不可重复读在每次查询时都生成一个ReadView
    * 根据ReadView可以判断某一事务是否在生成ReadView之前就提交了
    * 每次查询时根据ReadView去遍历版本链查找合适的版本数据，就是那些在生成ReadView时就已经提交的数据
    * 二级索引虽然没有隐藏列，但是页面头部信息记录有最后一次修改该页面的事务ID，
        如果不能确定该事务ID对应的事务已经提交则必须回表查询

| 隔离级别 | 并发问题   | 解决方案 |
|----------|------------|----------|
|          | 脏写       | 互斥锁   |
| 未提交读 | 脏读       | MVCC     |
| 已提交读 | 不可重复读 | MVCC     |
| 可重复读 | 幻读       | 间隙锁   |
| 串行化   |            |          |

* 持久性：一旦事务提交则其所做的修改就会永久保存到数据库中          **(Redo Log与双写缓冲区)**
    * 在事务提交前，会先将Redo Log写入磁盘，Redo Log其实相当于增量备份，数据量很小，
        当系统意外宕机时，重启系统后可以根据它来恢复页面数据
    * 脏页会在适当的时候冲刷到磁盘，而非事务一提交就冲刷
    * 先将脏页冲刷到磁盘双写缓冲区备份，再冲刷到对应的页面位置；
        因为如果直接冲刷到对应页面中而中途宕机了，这时候页面数据不完整，是无法通过Redo Log恢复的；
        冲刷备份到双写缓冲区可应对这种情况；
        虽然冲刷了两倍的数据，但时间开销却不是两倍，因为IO密集型应用的性能瓶颈与IO次数有关

* 锁
    * 当一个事务读取某一页面时，对这个页面加共享锁
    * 读取完毕后释放页面的共享锁，并对检索的行加间隙锁

    * 当一个事务修改某一页面时，对这个页面加互斥锁
    * 修改完毕后释放页面的互斥锁，并对修改的行加互斥锁
    * 因为MVCC，其他事务可以并发读取被该事务锁住的行

#### 索引
* Hash索引：支持全键匹配
* B+Tree索引：支持前缀匹配、范围查询、索引排序与分组


* 聚簇索引
    * 要点：将索引与行记录放在一起
    * 优点：将相关数据放在一起可避免随机IO
    * 缺点：插入速度严重依赖主键顺序
* 伪哈希索引
    * 要点：利用哈希函数将字符串映射为数字
    * 优点：减小索引大小且大幅加速字符串比较过程
    * 缺点：仅支持全键匹配
* 前缀索引
    * 要点：根据索引选择性(基数/总数)选取适当长度前缀
    * 优点：一定程度减小索引大小并加速字符串比较过程
    * 缺点：仅适用于`LIKE 'prefix%'`
* 复合索引
    * 要点：将索引选择性/单独查询频率/等值查询频率较高的放在前面
    * 优点：可优化`WHERE ... AND ...`
    * 缺点：无法跳过前缀列（可用`IN`来尝试解决）


* 索引合并：通过按主键合并多个二级索引(顺序IO)结果集来代替回表查询(随机IO)
    * 交集合并
        * 二级索引全键匹配`AND`二级索引全键匹配
        * 二级索引全键匹配`AND`主键索引范围匹配
    * 并集合并
        * 二级索引全键匹配`OR`二级索引全键匹配
        * 二级索引全键匹配`OR`主键索引范围匹配
        * 二级索引全键匹配`OR`交集合并结果
    * 并集排序
        * 二级索引范围匹配`OR`二级索引范围匹配


* 单表查询
    * 尝试进行索引合并
    * 选取一条最优索引
        * 全键匹配或范围查询或索引扫描
        * 回表查询
    * 服务层利用`WHERE`过滤


* 联结查询
    * 对驱动表进行条件过滤（单表查询）
    * 循环取出驱动表中行到join buffer来过滤被驱动表（单表查询）


### 服务架构
* 域名解析
    * 全局负载均衡(GSLB)：根据用户地理位置与网络运营商返回响应VIP从而让用户就近接入，并实现全局的流量调度与负载均衡

* 反向代理
    > 对外表现为一个服务器(Name:VIP:Port)，转发后通过某一Node(IP:Port)进入集群
    * 四层转发：IP收敛，负载均衡，透明多通，RS自动剔除，多级容灾
    * 七层转发：协议卸载，负载均衡

![K8S动态将Nodes组建成一个集群并在其中调度管理Pods，每个Pod就是一个逻辑主机](images/components-of-kubernetes.svg)

* 容器集群
    * namespace ：将K8S集群划分为若干个资源不可共享的虚拟集群
    * Ingress   ：管理集群外部访问，提供负载均衡、SSL终结和基于名称的虚拟托管（七层转发，主外）
    * Service   ：即使Pod的IP动态变化也能通过Service(Name or IP)访问其后的Pod（四层转发，主内）
    * Deployment：管控Pod运行在用户期望状态中（调度、恢复等等）

### 业务流程
1. 与产品一起拆分独立子需求，并创建tapd单
2. 每个需求对应一个分支名，前后端创建同名分支
3. 开发时及时流转tapd单，且代码提交关联tapd单
4. 触发提测流水线
5. 合入test/prerelease/release/master都需要走MR
