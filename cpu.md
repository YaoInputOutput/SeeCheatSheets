# 目录
<!-- vim-markdown-toc GFM -->

- [逻辑电路](#逻辑电路)
  - [逻辑门](#逻辑门)
  - [经典组合逻辑](#经典组合逻辑)
  - [加法器](#加法器)
  - [触发器](#触发器)
- [处理器设计](#处理器设计)
- [现代微处理器](#现代微处理器)
- [高速缓存](#高速缓存)
- [性能优化](#性能优化)

<!-- vim-markdown-toc -->

# 逻辑电路
## 逻辑门
![ljm](images/ljm.png)

&emsp;基础的逻辑门只有与门(串联)、或门(并联)、非门(反相器)，他们之间互相组合可构成其它6种基础逻辑门。
注意观察上图最右边的表格，图片来自维基百科，将右侧的表格转换成如下格式可更直观的观察逻辑门之间的关系。

&emsp;第一行的0、1表示逻辑门第一个输入，第一列的0、1表示第二个输入，其它地方的0、1表示输出

| AND | 0   | 1   |
|-----|-----|-----|
| 0   | *0* | *0* |
| 1   | *0* | *1* |

&emsp;将与门的表格的取反可得到与非门

| NAND | 0   | 1   |
|------|-----|-----|
| 0    | *1* | *1* |
| 1    | *1* | *0* |

&emsp;再观察或门

| OR | 0   | 1   |
|----|-----|-----|
| 0  | *0* | *1* |
| 1  | *1* | *1* |

&emsp;将或门和与非门的输出连接到同一个与门的输入，得到异或门

| XOR | 0   | 1   |
|-----|-----|-----|
| 0   | *0* | *1* |
| 1   | *1* | *0* |

![xor](images/xor.png)

&emsp;其它逻辑门同理。组合逻辑的设计其实就如同布尔代数一般。

## 经典组合逻辑
&emsp;与门的输入必须全为1，则其输出才为1。而只要我们控制其中一个输出为0，则与门输出就总是0。
所以与门天生就是做分支逻辑的料。
> 以下图片来自[知乎@JoshCena](https://zhuanlan.zhihu.com/p/107009452)

![zuhe](images/zuhe.jpg)

**编码器**

![bmq](images/bmq.png)

**选择器**。将所有输入数据Dn撤销后得到**译码器**。将输入数据换成唯一的D得到**分配器**。

![xzq](images/xzq.png)

## 加法器
&emsp;将二进制加法拆分为求和位与求进位，如$1+1$，和位为0，但向高位进一，则进位为1，的和为$01$

| 和位 | *0* | *1* |
|------|-----|-----|
| 0    | *0* | *1* |
| 1    | *1* | *0* |

| 进位 | *0* | *1* |
|------|-----|-----|
| 0    | *0* | *0* |
| 1    | *0* | *1* |

&emsp;发现没有，和位就是异或门，进位就是与门！于是设计半加器如下。
S为和位输出，C为进位输出。

![bjq](images/bjq.png)

&emsp;将输入A、B扩展为多位的二进制数时，必定需要将当前二进制位和位与低位运算的进位相加（第二个半加器），
相加所得和位即为当前位运算的结果位。
而将该进位进位与当前位的进位相加（第三个半加器），如此半加器又产生了新的和位与进位。
此时问题出现了，我们原本设计应该是3个输入和2个输出（S、C）。
但目前我们已经使用了3个半加器，得到3个输出
咋回事？

![plus](images/plus.png)

&emsp;数学上来讲，三个二进制位相加只有4种结果——00、01、10、11。两位输出S与C完全能表达这4种结果。
那到底是哪里出问题了呢？

&emsp;再观察观察和位与进位的运算表，发现没有，S与C不可能同时为1。
所以当S1（第1个半加器的S）为1时，CO1必定为0；反之，当CO1为1时，S必为0。
当S1为0时，CO2也必定为0。所以导致CO2与CO1不可能同时为1。
**也就是说，第三个半加器的进位输出必定为0，而其和位输出S3作为整个全加器设计的进位输出**

| S3 | 0   | 1   |
|----|-----|-----|
| 0  | *0* | *1* |
| 1  | *1* | -   |

&emsp;`-`表示该情况不存在，则完全可以利用或门取代第三个半加器。最终全加器见下

![allplus](images/allplus.png)

封装并扩展多位后得

![maplus](images/maplus.png)

**减法**

&emsp;关于减法，主要问题是需要向高位借位。为避免借位，可以如此计算减法（以4位二进制为例）

$$x - y = 1111 - y + x + 1 - (1111 + 1) = ~y + 1 + x - 10000$$

&emsp;如此一来，仅有的减法是减去10000，不可能导致借位。而且我们只关心低4位，
高位结果被简单丢弃。

$$x + (-y) = x + (~y + 1)$$

&emsp;嗯哼。发现没有，`-y = ~y + 1`，这不就是补码求逆元(求反)公式吗？
没错，这就是补码的由来。

&emsp;将n位二进制位表示的数字空间中一半的容量拿出来表示负数，
以四位二进制位为例，从正数1开始，1为0001，则-1为1111。
如此计算，直到7(0111)与-7(1001)。
最后还剩0000与1000还未使用，毫无疑问0000用来表示0，
那1000呢，是表示8呢还是表示-8呢？

&emsp;当然，如今我们知道，1000表示的应该是-8，这样一来补码的表示便有了简洁的数学公式。

$向量\overrightarrow{x}=[x_{w-1},\space x_{w-2},\space ...,\space x_0]$
$$B2T_w(\overrightarrow{x})\doteq-x_{w-1}2^{w-1}+\sum^{w-2}_{i=0}x_i2^i$$

## 触发器
&emsp;想象一下，如果将一个逻辑门的输出连接到它输入会怎么样？
该逻辑门的输出就可能改变它的输入，
比如或非门只要有一个输入为1则输出为0，而输出改变又导致输入变为全0，输出又变为1，又导致输入...

&emsp;逻辑门的输出与上次的输入有关，理论上，可以找到一种方法设计出一个组合逻辑用于记忆上次输入。
于是两位英国无线电物理学家在1918年发明了触发器。

![g](images/ifq.jfif)

| S | R | Q | $\bar{Q}$ |
|---|---|---|-----------|
| 1 | 0 | 1 | 0         |
| 0 | 1 | 0 | 1         |
| 0 | 0 | Q | $\bar{Q}$ |
| 1 | 1 | 0 | 0         |

&emsp;S表示置位，R表示复位，Q表示设置的输出，$\bar{Q}$表示Q的反相（为保证这层抽象，应该禁止S与R均为1的情况出现）。
注意，当S与R皆为0时，输出保持不变，这就是我们希望的记忆功能。
可利用其制作**锁存器**

将上面触发器稍微改进一下，用时钟信号控制输入的有效性。
此为**电平触发器**（时钟处于高电平状态时即可触发）。

![s](images/dpifq.png)

此时当时钟信号为1时，只要输入改变，输出也会跟着改变。
若本应在下个时钟周期的输入提早到来，则可能导致错误的输出。
再改进一下，利用两个电平触发器结合，得到**边沿触发器**（只在时钟上沿的一瞬间触发）

![bmifq](images/byifq.png)

观察一下周期图，输出只在时钟上沿瞬间改变，而且周期翻倍了。

![vq](images/vq.png)

**计数器** 

![juq](images/juq.png)

把下面的周期图顺时针旋转90度再从上往下看看。

![vq](images/vq.jfif)

Surprise！计数器大功告成。

# 处理器设计
&emsp;将各个逻辑电路组合在一起，并暴露出输入接口与输出接口，就可以实现各种各样的数据处理。

&emsp;最初，人们通过手动输入数据。后来，很自然地想到，将输入数据放在某个地方，
让处理器从该位置自动顺序读取数据指令与数据，而这些指令有可以控制处理器进行跳转而读取其他地方的指令。
于是，整个过程都**自动化**了，我们只需要提前编写好程序并放到某个位置，而这个位置就有存储器扮演。

*<p align="center">冯诺依曼结构</p>*

![fnym](images/fnym.gif)

利用计数器、选择器、触发器(锁存器)实现顺序读取内存。
![cpu](images/cpu.png)

&emsp;这样一笔一划的利用图纸来设计处理器无疑是效率低下的，于是诞生了HDL(硬件描述语言)。
HDL是一种文本表示，看上去和编程语言类似，但是它是用来描述结构而非过程的。
最常用的语言是Verilog，语法类似C。另一种是VHDL，语法类似Ada。
提高生产效率的方式无非就是提供高级抽象与可复用对象。就像C语言之于汇编，OOP之于POP。而HDL也是如此。

**处理器设计** 

&emsp;步入正题，现代处理器都利用了流水线来提高性能。
想要设计出流水线，就要将指令进行“动作分解”。但不同指令、不同动作锁需要的时间很可能是不同的，
想要处理器正常工作，将各个阶段进行同步是必须的，于是引入了时钟寄存器来作流水线屏障。
PS:是不是觉得边沿触发器正合此意？

CPE并发性能计算：
* 流水线的发射时间：$L=\frac{(指令延迟\times指令数 + 流水线长度延迟)}{指令数}$，
发射时间指同类型指令之间需要的时间间隔
* 指令级并行的指令延迟：$\frac{L}{指令并行度}$

&emsp;将指令划分为更多阶段则可以提高指令吞吐量，但因为时钟寄存器也需要时间来传递逻辑流，
所以也会增大指令延迟。以下为《CSAPP》中设计的Y86指令集架构的五流程流水线处理器的结构示意图。
具体设计代码请参考原书。

![pipe](images/pipecpu.jpg)

**关于分支预测**

&emsp;反向选择，若跳转地址比下一条指令地址低则选择；
正向不选择，若跳转地址比下一条指令地址高则不选择。
目的都是为了预测进入循环体，因为循环体代码一般会执行多次。

&emsp;还有过程调用的返回地址判断，高性能处理器会在取指单元放入一个硬件栈，保存`call`指令产生的返回地址。
当取指`ret`时就从这个栈中弹出值作为预测返回地址，当然预测失败也需要进行恢复。

**关于流水线冒险** 
* 数据冒险：指令从寄存器或内存中读取的值，可能已被流水线中之前的指令更新但还未被写回。
* 控制冒险：分支预测失败需要恢复机制
* 异常：指令出错需要产生异常控制流并处理之

# 现代微处理器
**指令集架构** 

&emsp;一个处理器支持的指令和指令的字节级编码称为它的ISA(指令集架构)。
说到指令集架构，就不得不提RSIC与CISC的历史了。

&emsp;RSIC(复杂指令集)其实先于CSIC(精简指令集)诞生。
CSIC的思想就是利用一个个简洁的指令简化CPU设计，并利用流水线提高指令的吞吐量。
因为当时RSIC中许多高级指令其实很难被编译器产生，故也很少用到这些指令；
再者，复杂的指令通常需要多个时钟周期来完成，很占用资源。

&emsp;当然，如今看来，RSIC与CSIC的界限早已模糊，CSIC中有了更多、更复杂的指令，
而RSIC也引入了流水线的设计。双方取长补短，都有了长足的进步。
现在，x86与ARM就是RSIC与CSIC的代表了。ARM相比x86，凭借更低的成本与能耗在移动端市场混的风生水起。

**现代处理器结构**

![xdcpu](images/xdcpu.png)

&emsp;主要分为ICU(指令控制单元)与EU(执行单元)两部分。
前者主要负责提前取指并译码为各个微操作再发射给EU，此外，ICU中的退役单元还负责解决数据冒险。
在EU中存在着多条流水线，可并行执行多个操作，而每条流水线可以执行多种操作。
因为有了这些流水线，我们才能利用指令集并行来优化程序性能。

![yj](images/pin.jpg)
&emsp;CPU作为主板上的主要芯片，一般是可拔插的。
之前的文章说过，CPU将组合逻辑打包封装，只暴露出一些接口线路来与整个系统进行交互。
这些接口就是引脚，如今Intel使用LGA(栅格阵列封装)，它的特点是用金属触点式封装取代了以往的针状插脚。
而常见的ADM接口是PGA(插针网格阵列封装)。而每个暴露出来的引脚都有不同的功能。

![8086](images/8086.png)

# 高速缓存
![ciqu](images/ciqu.jpg)

&emsp;访问越快速的存储器，也越昂贵，导致容量也越小。于是形成了上图那样的存储层次结构。
而在CPU内部有三级高速缓存，它们一般为SRAM。

*CPU内部的哈佛结构*

![cache](images/cache.jfif)

**局部性原理**
> 两种局部性都可以增大缓存命中率
* 良好的时间局部性是指被引用过一次的内存位置很可能在不久的将来再被多次引用
* 良好的空间局部性是指被引用过一次的内存位置，很可能在不久的将来引用其附近一个内存位置

**缓存地址**

![cache](images/cache.jpg)

&emsp;内存地址被分为三部分，因为不命中时会驱除目标组中的块，所以为了提高空间局部性，
尽可能能够将连续的块加载如高速缓存，则应该每组进行均摊，于是并未分割高段为组索引，
而是取中段地址为组索引，如此一来，加载连续的块时会均摊到每个组，
而不是一下子全加载到一个组而可能导致“抖动”。

&emsp;缓存读不命中的驱逐策略：LFU(频率最低者)，LRU(最旧引用者)

&emsp;缓存写不命中的处理方式：写分配（从低级缓存中加载到高速缓存再写），
写不分配（直接写入低级缓存）。对于前者需要额外的硬件来标记并处理脏数据。
低级缓存倾向与写分配（因为数据传送时间长）。

* 高速缓存参数
    * 不命中率
    * 命中率
    * 命中时间
    * 不命中处罚
* 影响因素
    * 缓存大小：越大命中率越高，但也越难越贵
    * 块大小：在缓存大小一定的情况下，块越大则空间局部性越好，但时间局部性越差；同时增加了不命中处罚
    * 相联度：更高的相联度需要更复杂的硬件与处理机制，也就越贵且增加了命中时间与不命中处罚。
    对于局部性的影响倒是与“块大小”相反。一般在高级缓存中选择较高相联度(处罚很小)，而在低级缓存中使用较低相联度

![mountain](images/mountain.jpg)

存储器山说明，编写步长越小，局部性越高，总数据据越接近高速缓存容量，则性能越好。
步长小时高性能CPU还会对数据进行预取来优化性能

# 性能优化
* 减少冗余开销
    > 用临时变量保存中间结果来减少内存引用。  
    > 将冗余函数调用移出循环来减少函数调用。
* 循环展开
    > 减少循环次数
* 累积变量
    > 充分利用指令集并行
* 重新结合
    > 减少循环片段间的相互依赖关系，充分利用流水线
* 局部性
    > 结合CPU高速缓存大小与存储器山的指导，尽量让局部数据全部存入高速缓存

<!--
逻辑门、选择器与编码器、触发器
流水线、指令级并行、减少冗余
高速缓存、局部性、内循环步长
-->
